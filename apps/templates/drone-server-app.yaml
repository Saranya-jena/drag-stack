apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: drone-server
  namespace: argocd
  # Add this finalizer ONLY if you want these to cascade delete.
  finalizers:
    - resources-finalizer.argocd.argoproj.io
  labels:
    name: drone
spec:
  project: dag-project
  source:
    repoURL: https://charts.drone.io 
    targetRevision: {{ .Values.spec.drone.server.version }} 
    path: {{ .Values.spec.drone.server.valuesPath }}
    chart: drone/drone  
    helm:
      releaseName: drone-server
      # Helm values files for overriding values in the helm chart
      # The path is relative to the spec.source.path directory defined above
      # valueFiles:
      # - drone-server/values.yaml

      # Values file as block file
      values: |
        service:
          # the Drone Kubernetes service type
          type: NodePort
          port: 8080
          # this port will be used in KinD extra port mappings to allow accessing the 
          # drone server from our laptops
          nodePort: 30980
          
        extraSecretNamesForEnvFrom:
          # all the other as $PROJECT_HOME/k8s/.env variables are loaded via this secret
          # https://docs.drone.io/server/reference/
          - {{ .Values.spec.gitea.oAuth.secret }}

        env:
          # the Drone server host typically what the drone runners will use to 
          # communicate with the server
          DRONE_SERVER_HOST: {{ .Values.spec.drone.server.host }}
          # Since we run Gitea in http mode we will skip TLS verification
          DRONE_GITEA_SKIP_VERIFY: true
          # The url where Gitea could be reached, typically used while 
          # cloning the sources
          # https://docs.drone.io/server/provider/gitea/
          DRONE_GITEA_SERVER: {{ .Values.spec.gitea.server }}
          # For this local setup and demo we wil run Drone in http mode
          DRONE_SERVER_PROTO: http

      # Optional Helm version to template with. If omitted it will fall back to look at the 'apiVersion' in Chart.yaml
      # and decide which Helm binary to use automatically. This field can be either 'v2' or 'v3'.
      version: v2

    # plugin specific config
    # plugin:
    #   # Only set the plugin name if the plugin is defined in argocd-cm.
    #   # If the plugin is defined as a sidecar, omit the name. The plugin will be automatically matched with the
    #   # Application according to the plugin's discovery rules.
    #   name: mypluginname
    #   # environment variables passed to the plugin
    #   env:
    #     - name: FOO
    #       value: bar

  # Destination cluster and namespace to deploy the application
  destination:
    server: {{ .Values.spec.destination.server }}
    # The namespace will only be set for namespace-scoped resources that have not set a value for .metadata.namespace
    namespace: {{ .Values.spec.drone.server.namespace }}

  # Sync policy
  syncPolicy:
    automated: # automated sync by default retries failed attempts 5 times with following delays between attempts ( 5s, 10s, 20s, 40s, 80s ); retry controlled using `retry` field.
      prune: true # Specifies if resources should be pruned during auto-syncing ( false by default ).
      selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ).
      allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ).
    syncOptions:     # Sync options which modifies sync behavior
    - Validate=false # disables resource validation (equivalent to 'kubectl apply --validate=false') ( true by default ).
    - CreateNamespace=true # Namespace Auto-Creation ensures that namespace specified as the application destination exists in the destination cluster.
    - PrunePropagationPolicy=foreground # Supported policies are background, foreground and orphan.
    - PruneLast=true # Allow the ability for resource pruning to happen as a final, implicit wave of a sync operation
    # The retry feature is available since v1.7
    retry:
      limit: 5 # number of failed sync attempt retries; unlimited number of attempts if less than 0
      backoff:
        duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
        factor: 2 # a factor to multiply the base duration after each failed retry
        maxDuration: 3m # the maximum amount of time allowed for the backoff strategy

  # Will ignore differences between live and desired states during the diff. Note that these configurations are not
  # used during the sync process.
  ignoreDifferences:
  # for the specified json pointers
  - group: apps
    kind: Deployment
    jsonPointers:
    - /spec/replicas
  # for the specified managedFields managers
  - group: "*"
    kind: "*"
    managedFieldsManagers:
    - kube-controller-manager
